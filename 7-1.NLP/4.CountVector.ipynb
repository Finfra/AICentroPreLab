{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Make Document-Term Matrix (Basic)\n",
    "* 장점 : 학습용(과정 이해)\n",
    "* 단점 : 코드가 복잡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All string : 고인물은 게임을 즐긴다. 남중호는 게임을 잘한다. 남중구는 게임을 못한다. 나는 나를 사랑한다 너의 게임 나의 게임 사랑하라\n"
     ]
    }
   ],
   "source": [
    "corpus = [\n",
    "    \"고인물은 게임을 즐긴다.\",\n",
    "    \"남중호는 게임을 잘한다.\",\n",
    "    \"남중구는 게임을 못한다.\",\n",
    "    \"나는 나를 사랑한다\",\n",
    "    \"너의 게임 나의 게임 사랑하라\"\n",
    "]\n",
    "s=\" \".join(corpus)\n",
    "\n",
    "print('All string :' ,s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tockents: 인물 게임 남 중호 게임 남중구 게임 나 나 사랑 너 게임 나 게임 사랑\n"
     ]
    }
   ],
   "source": [
    "# posToUse=[\"NNP\",\"NNG\",\"MAG\",\"NP\",\"VV\",\"VV+EF\"]\n",
    "posToUse=[\"NNP\",\"NNG\",\"NP\"]\n",
    "def getTokens(s):\n",
    "    global posToUse\n",
    "    return \" \".join([ i[0] for i in  Mecab().pos(s) if i[1] in posToUse ] )\n",
    "    \n",
    "print('All tockents:', getTokens(s))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        게임  5\n",
      "         나  3\n",
      "        사랑  2\n",
      "        인물  1\n",
      "         남  1\n",
      "        중호  1\n",
      "       남중구  1\n",
      "         너  1\n"
     ]
    }
   ],
   "source": [
    "# Document Frequency\n",
    "from collections import Counter\n",
    "counts=Counter(getTokens(s).split())\n",
    "counts_sorted=sorted(counts, key=counts.get,reverse=True)\n",
    "for i in counts_sorted:\n",
    "    print(\"%10s %2d\"%(i,counts[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'게임': 1, '나': 2, '사랑': 3, '인물': 4, '남': 5, '중호': 6, '남중구': 7, '너': 8}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx = {word: ii for ii, word in enumerate(counts_sorted,1)}\n",
    "word2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ind2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: '게임', 2: '나', 3: '사랑', 4: '인물', 5: '남', 6: '중호', 7: '남중구', 8: '너'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind2word = {ii: word for ii, word in enumerate(counts_sorted,1)}\n",
    "ind2word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Term Frequency Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '인물 게임', array([1, 0, 0, 1, 0, 0, 0, 0])),\n",
       " (1, '남 중호 게임', array([1, 0, 0, 0, 1, 1, 0, 0])),\n",
       " (2, '남중구 게임', array([1, 0, 0, 0, 0, 0, 1, 0])),\n",
       " (3, '나 나 사랑', array([0, 2, 1, 0, 0, 0, 0, 0])),\n",
       " (4, '너 게임 나 게임 사랑', array([2, 1, 1, 0, 0, 0, 0, 1]))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getDtm(corpus,word2idx):\n",
    "    dicCount=len(word2idx)\n",
    "    cv_org=np.zeros(dicCount, dtype=np.int)\n",
    "    dtm=[(i, getTokens(doc),cv_org.copy()) for i,doc in enumerate(corpus)]\n",
    "    for r in dtm:\n",
    "        cv=r[2]\n",
    "        counts=Counter(r[1].split())\n",
    "        for k in counts.keys():\n",
    "            dtm[r[0]][2][word2idx[k]-1]=dtm[r[0]][2][word2idx[k]-1]+counts[k]\n",
    "#         print(r[2])    \n",
    "    return dtm\n",
    "\n",
    "getDtm(corpus,word2idx)\n",
    "# print('DTM: ',vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Document-Term Matrix by scikit-learn\n",
    "* 장점 : 구현이 쉽다.\n",
    "* 주의 : StopWord나 글자 1글자 단어가 되려면 tokenizer 옵션 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Very Simple Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aa': 0, 'aaa': 1, 'bb': 2, 'bbb': 3, '나나': 4, '나나나': 5}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# cf) for English : word2idx  \n",
    "vect = CountVectorizer()\n",
    "vect.fit(['a aa aaa b bb bbb 나 나나 나나나'])\n",
    "getTokens(s)\n",
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All string : 고인물은 게임을 즐긴다. 남중호는 게임을 잘한다. 남중구는 게임을 못한다. 나는 나란 놈 사랑한다.18 너의 게임 나의 게임 사랑하라\n",
      "All tockents: ['인물', '게임', '남', '중호', '게임', '남중구', '게임', '나', '나', '놈', '사랑', '너', '게임', '나', '게임', '사랑']\n"
     ]
    }
   ],
   "source": [
    "corpus = [\n",
    "    \"고인물은 게임을 즐긴다.\",\n",
    "    \"남중호는 게임을 잘한다.\",\n",
    "    \"남중구는 게임을 못한다.\",\n",
    "    \"나는 나란 놈 사랑한다.18\",\n",
    "    \"너의 게임 나의 게임 사랑하라\"\n",
    "]\n",
    "s=\" \".join(corpus)\n",
    "\n",
    "print('All string :' ,s)\n",
    "\n",
    "# posToUse=[\"NNP\",\"NNG\",\"MAG\",\"NP\",\"VV\",\"VV+EF\",\"IC\"]\n",
    "posToUse=[\"NNP\",\"NNG\",\"NP\",\"NNB\"]\n",
    "\n",
    "def getTokens(s):\n",
    "    global posToUse\n",
    "    return [ i[0] for i in  Mecab().pos(s) if i[1] in posToUse ] \n",
    "    \n",
    "print('All tockents:', getTokens(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simple Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary :  {'인물': 3, '게임': 0, '중호': 4, '남중구': 1, '사랑': 2}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 1],\n",
       "       [1, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [2, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer()\n",
    "vect.fit(getTokens(s))\n",
    "print('Dictionary : ',vect.vocabulary_)\n",
    "\n",
    "vect.transform([\" \".join(getTokens(i)) for i in corpus]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. tokenizer 사용 Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary :  {'인물': 7, '게임': 0, '남': 2, '중호': 8, '남중구': 3, '나': 1, '놈': 5, '사랑': 6, '너': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [1, 0, 1, 0, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 2, 0, 0, 0, 1, 1, 0, 0],\n",
       "       [2, 1, 0, 0, 1, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posToUse=[\"NNP\",\"NNG\",\"NP\",\"NNB\"]\n",
    "vect = CountVectorizer(tokenizer=getTokens)\n",
    "vect.fit(getTokens(s))\n",
    "print('Dictionary : ',vect.vocabulary_)\n",
    "vect.transform([\" \".join(getTokens(i)) for i in corpus]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. tokenizer+stopword 적용 Version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary :  {'인물': 6, '게임': 0, '남': 2, '중호': 7, '남중구': 3, '나': 1, '사랑': 5, '너': 4}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [1, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 2, 0, 0, 0, 1, 0, 0],\n",
       "       [2, 1, 0, 0, 1, 1, 0, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posToUse=[\"NNP\",\"NNG\",\"NP\",\"NNB\"]\n",
    "stopwords=[\"놈\",\"18\"]\n",
    "def getToken(s,pos=posToUse,stopword=stopwords):\n",
    "    return [ w for w,t in  Mecab().pos(s) if t in pos and w not in stopword ] \n",
    "vect = CountVectorizer(tokenizer=getToken)\n",
    "vect.fit(getTokens(s))\n",
    "print('Dictionary : ',vect.vocabulary_)\n",
    "vect.transform([\" \".join(getTokens(i)) for i in corpus]).toarray()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
