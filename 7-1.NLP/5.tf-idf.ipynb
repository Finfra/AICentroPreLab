{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from konlpy.tag import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make DTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All string : 고인물은 게임을 즐긴다. 남중호는 게임을 잘한다. 남중구는 게임을 못한다. 나는 나를 사랑한다 너의 게임 나의 게임 사랑하라\n",
      "All tockents: 인물 게임 남 중호 게임 남중구 게임 나 나 사랑 너 게임 나 게임 사랑\n"
     ]
    }
   ],
   "source": [
    "corpus = [\n",
    "    \"고인물은 게임을 즐긴다.\",\n",
    "    \"남중호는 게임을 잘한다.\",\n",
    "    \"남중구는 게임을 못한다.\",\n",
    "    \"나는 나를 사랑한다\",\n",
    "    \"너의 게임 나의 게임 사랑하라\"\n",
    "]\n",
    "s=\" \".join(corpus)\n",
    "\n",
    "print('All string :' ,s)\n",
    "\n",
    "# posToUse=[\"NNP\",\"NNG\",\"MAG\",\"NP\",\"VV\",\"VV+EF\"]\n",
    "posToUse=[\"NNP\",\"NNG\",\"NP\"]\n",
    "def getTokens(s):\n",
    "    global posToUse\n",
    "    return \" \".join([ i[0] for i in  Mecab().pos(s) if i[1] in posToUse ] )\n",
    "    \n",
    "print('All tockents:', getTokens(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['인물 게임', '남 중호 게임', '남중구 게임', '나 나 사랑', '너 게임 나 게임 사랑']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus2=[getTokens(d) for d in corpus]\n",
    "corpus2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'인물': 6, '게임': 0, '남': 2, '중호': 7, '남중구': 3, '나': 1, '사랑': 5, '너': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "posToUse=[\"NNP\",\"NNG\",\"NP\",\"NNB\"]\n",
    "stopwords=[\"놈\",\"18\"]\n",
    "def getToken(s,pos=posToUse,stopword=stopwords):\n",
    "    return [ w for w,t in  Mecab().pos(s) if t in pos and w not in stopword ] \n",
    "\n",
    "dtm_tfidf = TfidfVectorizer(tokenizer=getToken).fit(corpus2)\n",
    "#cf) dtm_tfidf = TfidfVectorizer(ngram_range=(0,2),min_df=2).fit(corpus2)\n",
    "print(dtm_tfidf.vocabulary_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.49084524 0.         0.         0.         0.         0.\n",
      "  0.87124678 0.        ]\n",
      " [0.37008621 0.         0.65690037 0.         0.         0.\n",
      "  0.         0.65690037]\n",
      " [0.49084524 0.         0.         0.87124678 0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.89442719 0.         0.         0.         0.4472136\n",
      "  0.         0.        ]\n",
      " [0.59622779 0.42691491 0.         0.         0.52915002 0.42691491\n",
      "  0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(dtm_tfidf.transform(corpus2).toarray())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
